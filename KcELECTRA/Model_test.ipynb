{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b04781b4",
   "metadata": {},
   "source": [
    "### 그래픽 카드 설정 및 확인\n",
    "- 현재 kernal에서 버전 확인이 꼭 필요한 것들 확인\n",
    "- torch 버전이 2.5.1+cu121이 아닐 경우 아래의 주석 해제 후 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49aa07d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)       # 2.5.1\n",
    "print(torch.version.cuda)      # 12.1\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743a38c",
   "metadata": {},
   "source": [
    "CUDA 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525b52ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ccfec",
   "metadata": {},
   "source": [
    "## 성능 향상을 위한 함수\n",
    "#### Text 정제\n",
    "- huggingface에서 개발자가 공개한 성능을 높이기 위한 데이터 전처리 과정입니다. 특수문자 및 이모지 등을 제거합니다\n",
    "- 불용어는 제거하지 않습니다. 감정 모델에서는 불용어 또한 중요한 데이터일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcbce7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "emojis = ''.join(emoji.EMOJI_DATA.keys())\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣{emojis}]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "def clean(x): \n",
    "    x = pattern.sub(' ', x)\n",
    "    x = emoji.replace_emoji(x, replace='') #emoji 삭제\n",
    "    x = url_pattern.sub('', x)\n",
    "    x = x.strip()\n",
    "    x = repeat_normalize(x, num_repeats=2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f80ef",
   "metadata": {},
   "source": [
    "### 텍스트 정제 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e455bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 오늘 선배한테 혼났어 .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"나는 오늘 선배한테 혼났어 ★.\"\n",
    "cleaned_sentence = clean(sentence)\n",
    "print(cleaned_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e62274",
   "metadata": {},
   "source": [
    "#### 감정 매핑."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb656dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 카테고리 (모델의 class 순서)\n",
    "CATEGORIES = [\n",
    "    \"happy\",\n",
    "    \"embarrass\",\n",
    "    \"anger\",\n",
    "    \"unrest\",\n",
    "    \"damaged\",\n",
    "    \"sadness\",\n",
    "]\n",
    "\n",
    "# 이건 실제 csv에서 뽑아올 것.\n",
    "label_map = {\n",
    "    \"기쁨\": 0,     # happy\n",
    "    \"당황\": 1,     # embarrass\n",
    "    \"분노\": 2,     # anger\n",
    "    \"불안\": 3,     # unrest\n",
    "    \"상처\": 4,     # damaged\n",
    "    \"슬픔\": 5,     # sadness\n",
    "}\n",
    "\n",
    "NUM_LABELS = len(CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0503d1",
   "metadata": {},
   "source": [
    "# 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67543693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 걸린 시간: 0.019초\n",
      "문장당 평균: 0.005초\n",
      "문장: 오늘은 기분이 너무 좋아!\n",
      "예측 감정: happy\n",
      "확률 분포: {'happy': 0.9954, 'embarrass': 0.0008, 'anger': 0.0007, 'unrest': 0.0016, 'damaged': 0.0005, 'sadness': 0.001}\n",
      "------------------------------------------------------------\n",
      "문장: 화가 나서 견딜 수가 없어.\n",
      "예측 감정: anger\n",
      "확률 분포: {'happy': 0.0008, 'embarrass': 0.0146, 'anger': 0.9241, 'unrest': 0.0123, 'damaged': 0.0249, 'sadness': 0.0233}\n",
      "------------------------------------------------------------\n",
      "문장: 너무 불안하고 초조해.\n",
      "예측 감정: unrest\n",
      "확률 분포: {'happy': 0.0016, 'embarrass': 0.0125, 'anger': 0.0288, 'unrest': 0.9343, 'damaged': 0.0179, 'sadness': 0.0049}\n",
      "------------------------------------------------------------\n",
      "문장: 나 기분이 이상해\n",
      "예측 감정: unrest\n",
      "확률 분포: {'happy': 0.0068, 'embarrass': 0.0404, 'anger': 0.0795, 'unrest': 0.3857, 'damaged': 0.2655, 'sadness': 0.2221}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 모델이랑 토크나이저 불러오기.\n",
    "MODEL_DIR = r\"C:\\Users\\SSAFY\\Desktop\\WANG\\S13P31A106\\ai\\Classifier_Model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "model.eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 감정 카테고리 - 맨 위에 저장해놓은 그거\n",
    "CATEGORIES = [\"happy\", \"embarrass\", \"anger\", \"unrest\", \"damaged\", \"sadness\"]\n",
    "\n",
    "# 추론 함수. 여기에 txt를 넣으면 결과가 나옴.\n",
    "def predict_emotion(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=-1)\n",
    "        preds = probs.argmax(dim=-1)\n",
    "\n",
    "    results = []\n",
    "    for i, text in enumerate(texts):\n",
    "        results.append({\n",
    "            \"text\": clean(text),\n",
    "            \"pred_label\": CATEGORIES[preds[i].item()],\n",
    "            \"probabilities\": {CATEGORIES[j]: round(probs[i][j].item(), 4) for j in range(len(CATEGORIES))}\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# 넣을 문장 예시. 나중에는 사용자의 다이어리 내용이 들어갈 것.\n",
    "sample_texts = [\n",
    "    \"오늘은 기분이 너무 좋아!\",\n",
    "    \"화가 나서 견딜 수가 없어.\",\n",
    "    \"너무 불안하고 초조해.\",\n",
    "    \"나 기분이 이상해\",\n",
    "]\n",
    "\n",
    "a = time.time()\n",
    "results = predict_emotion(sample_texts)  # 전체 예측\n",
    "b = time.time()\n",
    "\n",
    "print(f\"전체 걸린 시간: {b - a:.3f}초\")\n",
    "print(f\"문장당 평균: {(b - a)/len(results):.3f}초\")\n",
    "\n",
    "for r in results:\n",
    "    print(f\"문장: {r['text']}\")\n",
    "    print(f\"예측 감정: {r['pred_label']}\")\n",
    "    print(\"확률 분포:\", r[\"probabilities\"])\n",
    "    print(\"-\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kcvenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
