{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd8184a1",
   "metadata": {},
   "source": [
    "## 초기 환경 세팅 및 확인\n",
    "1. requirements.txt 설치\n",
    "2. torch는 cuda버전을 사용하고 있으므로 사용자가 추가로 다운로드 필요\n",
    "3. 그래픽카드 사용 가능여부 확인\n",
    "    - get_device_name에서 안뜨면 그래픽카드 안잡힌것.\n",
    "    - 만약 안잡히면 !nvidia-smi 주석을 풀고 그래픽카드가 제대로 잡히는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477546cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d3e40d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "from config import ModelConfig as cf\n",
    "\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7cc9358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes==0.43.2\n",
      "  Downloading bitsandbytes-0.43.2-py3-none-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\jooyoung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bitsandbytes==0.43.2) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy in c:\\users\\jooyoung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bitsandbytes==0.43.2) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\jooyoung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->bitsandbytes==0.43.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\jooyoung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->bitsandbytes==0.43.2) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\jooyoung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->bitsandbytes==0.43.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jooyoung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->bitsandbytes==0.43.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jooyoung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->bitsandbytes==0.43.2) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jooyoung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch->bitsandbytes==0.43.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jooyoung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch->bitsandbytes==0.43.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jooyoung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch->bitsandbytes==0.43.2) (2.1.5)\n",
      "Downloading bitsandbytes-0.43.2-py3-none-win_amd64.whl (136.5 MB)\n",
      "   ---------------------------------------- 0.0/136.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/136.5 MB 49.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 3.7/136.5 MB 8.4 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 14.7/136.5 MB 23.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 18.6/136.5 MB 22.1 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 21.5/136.5 MB 20.3 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 23.1/136.5 MB 18.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 25.7/136.5 MB 17.3 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 33.6/136.5 MB 20.7 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 38.5/136.5 MB 20.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 41.4/136.5 MB 19.5 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 43.5/136.5 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 46.4/136.5 MB 18.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 46.9/136.5 MB 17.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 53.5/136.5 MB 18.2 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 54.5/136.5 MB 17.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 54.5/136.5 MB 17.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 55.6/136.5 MB 15.5 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 57.7/136.5 MB 15.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 59.8/136.5 MB 14.8 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 61.9/136.5 MB 15.2 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 66.1/136.5 MB 15.3 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 69.2/136.5 MB 14.9 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 73.4/136.5 MB 15.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 76.3/136.5 MB 15.0 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 79.2/136.5 MB 14.9 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 83.9/136.5 MB 15.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 86.0/136.5 MB 15.4 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 87.0/136.5 MB 15.0 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 93.3/136.5 MB 15.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 97.3/136.5 MB 15.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 100.1/136.5 MB 15.3 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 104.9/136.5 MB 15.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 109.1/136.5 MB 15.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 109.6/136.5 MB 15.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 117.4/136.5 MB 15.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 121.6/136.5 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 122.2/136.5 MB 15.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 122.7/136.5 MB 15.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 125.8/136.5 MB 15.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 126.9/136.5 MB 15.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 131.1/136.5 MB 15.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 132.1/136.5 MB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  133.2/136.5 MB 14.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  134.2/136.5 MB 14.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  136.3/136.5 MB 14.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 136.5/136.5 MB 14.2 MB/s  0:00:09\n",
      "Installing collected packages: bitsandbytes\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.43.0\n",
      "    Uninstalling bitsandbytes-0.43.0:\n",
      "      Successfully uninstalled bitsandbytes-0.43.0\n",
      "Successfully installed bitsandbytes-0.43.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\jooyoung\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~itsandbytes'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes==0.43.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d41795f",
   "metadata": {},
   "source": [
    "**torch로 그래픽카드가 잡히지 않을 때만 확인용으로 주석 제거 후 돌리기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df27cf1",
   "metadata": {},
   "source": [
    "## 모델 가져오기\n",
    "- 현재 파일에서는 QWEN3 0.6B 모델을 사용할 예정입니다.\n",
    "- 다른 모델을 사용하기 원할 경우 huggingface의 가이드에 따라 모델명을 변경하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a96c8f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True,   # 8비트로 당겨와서 GPU 메모리 절약할거임\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1821ab",
   "metadata": {},
   "source": [
    "### LORA를 통해 모델 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ae0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,293,760 || all params: 598,343,680 || trainable%: 0.3833515881708653\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Qwen은 Q/V projection에 적용\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# 파라미터가 1~200만 정도 수준이면 잘 된거\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ed36a",
   "metadata": {},
   "source": [
    "## 학습 시킬 데이터 셋. json 형식으로 준비할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb656dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"data/train.json\")\n",
    "\n",
    "def format_example(example):\n",
    "    return tokenizer(\n",
    "        f\"<|user|>: {example['instruction']}\\n<|assistant|>: {example['output']}\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(format_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8699216",
   "metadata": {},
   "source": [
    "## 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dcef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen3-finetuned\",     # 여기로 파인튜닝된 모델 저장\n",
    "    per_device_train_batch_size=2,      \n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92421e79",
   "metadata": {},
   "source": [
    "## LORA 가중치 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./qwen3-lora\")\n",
    "tokenizer.save_pretrained(\"./qwen3-lora\")\n",
    "\n",
    "from peft import merge_and_unload\n",
    "merged_model = merge_and_unload(model)\n",
    "merged_model.save_pretrained(\"./qwen3-merged\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
