{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec4ca4-795b-49ba-bd28-3f9a6d2b5603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ed6d6-753c-470e-9a4a-17a6ce90963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from config import ModelConfig as cf\n",
    "\n",
    "print(f\"TensorFlow 버전: {tf.__version__}\")\n",
    "print(f\"GPU 사용 가능: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f54ba9-cb47-4646-af6e-66e10e966f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cf.DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c5581-7467-4b0a-b33d-6b7286417a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeSequenceLength:\n",
    "    \"\"\"\n",
    "    시퀀스 길이를 정규화하는 클래스\n",
    "    - 패딩: 짧은 시퀀스를 0으로 채움\n",
    "    - 트리밍: 긴 시퀀스를 균등 샘플링\n",
    "    \"\"\"\n",
    "    \n",
    "    def pad_or_trim(self, seq: np.ndarray, target_len: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        시퀀스를 target_len 길이로 정규화\n",
    "        \n",
    "        Args:\n",
    "            seq: 입력 시퀀스 (2D array)\n",
    "            target_len: 목표 길이\n",
    "            \n",
    "        Returns:\n",
    "            정규화된 시퀀스\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 입력 검증\n",
    "            if seq is None or seq.size == 0:\n",
    "                raise ValueError(\"입력 시퀀스가 비어있습니다.\")\n",
    "            \n",
    "            if len(seq.shape) != 2:\n",
    "                raise ValueError(f\"시퀀스는 2차원 배열이어야 합니다. 현재 shape: {seq.shape}\")\n",
    "            \n",
    "            t, F = seq.shape\n",
    "            \n",
    "            if target_len <= 0:\n",
    "                raise ValueError(f\"target_len은 양수여야 합니다. 현재 값: {target_len}\")\n",
    "            \n",
    "            # 길이가 같으면 그대로 반환\n",
    "            if t == target_len:\n",
    "                return seq\n",
    "            \n",
    "            # 길이가 길면 샘플링\n",
    "            if t > target_len:\n",
    "                idx = np.linspace(0, t - 1, target_len).astype(int)\n",
    "                return seq[idx]\n",
    "            \n",
    "            # 길이가 짧으면 패딩\n",
    "            pad = np.zeros((target_len - t, F), dtype=seq.dtype)\n",
    "            return np.vstack([seq, pad])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"pad_or_trim 에러: {e}\")\n",
    "            raise\n",
    "\n",
    "    def nearest_bucket_len(self, t: int, buckets=cf.BUCKETS) -> int:\n",
    "        \"\"\"\n",
    "        현재 길이와 가장 가까운 버킷 길이를 반환\n",
    "        \n",
    "        Args:\n",
    "            t: 현재 시퀀스 길이\n",
    "            buckets: 사용 가능한 버킷 길이들\n",
    "            \n",
    "        Returns:\n",
    "            가장 가까운 버킷 길이\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if t <= 0:\n",
    "                raise ValueError(f\"시퀀스 길이는 양수여야 합니다. 현재 값: {t}\")\n",
    "            \n",
    "            if not buckets or len(buckets) == 0:\n",
    "                raise ValueError(\"버킷 리스트가 비어있습니다.\")\n",
    "            \n",
    "            if any(b <= 0 for b in buckets):\n",
    "                raise ValueError(\"모든 버킷 값은 양수여야 합니다.\")\n",
    "            \n",
    "            return min(buckets, key=lambda b: abs(b - t))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"nearest_bucket_len 에러: {e}\")\n",
    "            raise\n",
    "\n",
    "# 테스트\n",
    "normalizer = NormalizeSequenceLength()\n",
    "test_seq = np.random.rand(15, 195)  # 15프레임 시퀀스\n",
    "print(test_seq)\n",
    "normalized = normalizer.pad_or_trim(test_seq, 60)\n",
    "print(f\"원본: {test_seq.shape} → 정규화: {normalized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e344f4-6c0b-4230-a011-69f316611029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignLanguageModel:\n",
    "    \"\"\"\n",
    "    수어 인식을 위한 CNN + LSTM 하이브리드 모델\n",
    "    \n",
    "    특징:\n",
    "    - TimeDistributed CNN으로 프레임별 특징 추출\n",
    "    - LSTM으로 시계열 패턴 학습\n",
    "    - 버킷 기반 시퀀스 길이 정규화\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"모델 초기화\"\"\"\n",
    "        self.num_classes = cf.NUM_CLASSES\n",
    "        self.sequence_length = cf.SEQUENCE_LENGTH\n",
    "        self.feature_dim = cf.FEATURE_DIM\n",
    "        self.model = None\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.normalizer = NormalizeSequenceLength()\n",
    "        \n",
    "        print(f\"모델 설정:\")\n",
    "        print(f\"  - 시퀀스 길이: {self.sequence_length}\")\n",
    "        print(f\"  - 특성 차원: {self.feature_dim}\")\n",
    "        print(f\"  - 클래스 수: {self.num_classes}\")\n",
    "        print(f\"  - 버킷: {cf.BUCKETS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67dde3c-b26a-4a59-8fa2-53119fa5c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sequence_length(self, sequence: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    시퀀스 길이를 고정 길이로 정규화\n",
    "    \n",
    "    Args:\n",
    "        sequence: 입력 시퀀스 (2D array)\n",
    "        \n",
    "    Returns:\n",
    "        정규화된 시퀀스 (SEQUENCE_LENGTH 길이)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 입력 검증\n",
    "        if sequence is None or sequence.size == 0:\n",
    "            raise ValueError(\"입력 시퀀스가 비어있습니다.\")\n",
    "        \n",
    "        if len(sequence.shape) != 2:\n",
    "            raise ValueError(f\"시퀀스는 2차원 배열이어야 합니다. 현재 shape: {sequence.shape}\")\n",
    "        \n",
    "        # NaN 값 처리\n",
    "        sequence = np.nan_to_num(sequence, copy=False).astype(np.float32)\n",
    "        \n",
    "        # 고정 길이로 정규화\n",
    "        seq = self.normalizer.pad_or_trim(sequence, cf.SEQUENCE_LENGTH)\n",
    "        \n",
    "        return seq\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"normalize_sequence_length 에러: {e}\")\n",
    "        raise\n",
    "\n",
    "# SignLanguageModel 클래스에 메서드 추가\n",
    "SignLanguageModel.normalize_sequence_length = normalize_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5ae13-7fc1-4389-be04-7effcbc3ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class SignAugmentor:\n",
    "    def __init__(self, drop_prob=0.1, noise_std=0.01, scale_range=(0.9, 1.1), shift_range=(-2, 2)):\n",
    "        self.drop_prob = drop_prob\n",
    "        self.noise_std = noise_std\n",
    "        self.scale_range = scale_range\n",
    "        self.shift_range = shift_range\n",
    "\n",
    "    def temporal_dropout(self, sequence):\n",
    "        mask = np.random.rand(len(sequence)) > self.drop_prob\n",
    "        return sequence[mask] if mask.sum() > 0 else sequence\n",
    "\n",
    "    def temporal_shift(self, sequence):\n",
    "        shift = random.randint(*self.shift_range)\n",
    "        return np.roll(sequence, shift, axis=0)\n",
    "\n",
    "    def scale(self, sequence):\n",
    "        factor = random.uniform(*self.scale_range)\n",
    "        return sequence * factor\n",
    "\n",
    "    def add_noise(self, sequence):\n",
    "        noise = np.random.normal(0, self.noise_std, sequence.shape)\n",
    "        return sequence + noise\n",
    "\n",
    "    def mirror(self, sequence):\n",
    "        sequence[..., 0] *= -1\n",
    "        return sequence\n",
    "\n",
    "    def augment(self, sequence):\n",
    "        if random.random() < 0.5:\n",
    "            sequence = self.temporal_dropout(sequence)\n",
    "        if random.random() < 0.5:\n",
    "            sequence = self.temporal_shift(sequence)\n",
    "        if random.random() < 0.5:\n",
    "            sequence = self.scale(sequence)\n",
    "        if random.random() < 0.5:\n",
    "            sequence = self.add_noise(sequence)\n",
    "        if random.random() < 0.3:\n",
    "            sequence = self.mirror(sequence)\n",
    "        return sequence\n",
    "\n",
    "\n",
    "augmentor = SignAugmentor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098ebe1-5ca0-4336-a2f9-196b6492b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title npz 파일을 train/test로 나누기\n",
    "def load_processed_data(self, data_path, validation_person_ids=None, num_samples=None, random_state=42):\n",
    "    \"\"\"\n",
    "    전처리된 landmark 데이터 로드 및 person_id 기반 분할\n",
    "\n",
    "    Args:\n",
    "        data_path: 데이터 경로\n",
    "        validation_person_ids: 검증 세트로 사용할 person_id 리스트 (None이면 랜덤 분할)\n",
    "        num_samples: 로드할 샘플 수 (None이면 전체 로드)\n",
    "        random_state: 랜덤 시드 (재현성을 위해, validation_person_ids가 None일 때만 사용)\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_val, y_train, y_val: 분할된 학습/검증 데이터 (validation_person_ids가 None이면 X, y 전체 반환)\n",
    "        label_encoder: 학습된 LabelEncoder\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data_path = Path(data_path)\n",
    "\n",
    "        # 경로 검증\n",
    "        if not data_path.exists():\n",
    "            raise FileNotFoundError(f\"데이터 경로가 존재하지 않습니다: {data_path}\")\n",
    "\n",
    "        metadata_path = cf.DATA_ROOT / \"dataset_metadata.csv\"\n",
    "        if not metadata_path.exists():\n",
    "            raise FileNotFoundError(f\"메타데이터 파일이 존재하지 않습니다: {metadata_path}\")\n",
    "\n",
    "        # 메타데이터 로드\n",
    "        metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "        if metadata.empty:\n",
    "            raise ValueError(\"메타데이터가 비어있습니다.\")\n",
    "\n",
    "        # 컬럼 검증\n",
    "        required_columns = ['landmarks_file', 'word_gloss', 'word_id', 'person_id'] # person_id, word_id 추가\n",
    "        missing_columns = [col for col in required_columns if col not in metadata.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"메타데이터에 필요한 컬럼이 없습니다: {missing_columns}. person_id 컬럼이 필요합니다.\")\n",
    "\n",
    "        # 지정된 수의 샘플만 로드 (랜덤 선택)\n",
    "        if num_samples is not None and num_samples > 0:\n",
    "            if num_samples > len(metadata):\n",
    "                print(f\"경고: 요청된 샘플 수({num_samples})가 전체 데이터 수({len(metadata)})보다 많습니다. 전체 데이터를 로드합니다.\")\n",
    "            else:\n",
    "                # 메타데이터를 랜덤으로 섞고 지정된 수만큼 선택\n",
    "                metadata = metadata.sample(n=num_samples, random_state=random_state).reset_index(drop=True)\n",
    "                print(f\"{num_samples}개의 랜덤 샘플만 로드합니다.\")\n",
    "\n",
    "\n",
    "        # 데이터 로딩\n",
    "        X, y, person_ids = [], [], [] # person_ids 리스트 추가\n",
    "        failed_files = []\n",
    "\n",
    "        print(f\"총 {len(metadata)}개 파일 처리 중...\")\n",
    "\n",
    "        for idx, row in metadata.iterrows():\n",
    "            try:\n",
    "                landmarks_file = data_path / row['landmarks_file']\n",
    "                if landmarks_file.exists():\n",
    "                    landmarks_group = np.load(landmarks_file, allow_pickle=False)    # NPZ\n",
    "                    # print(f\"프레임 그룹 개수: {len(landmarks_group['x'])}\")\n",
    "\n",
    "                    # 프레임 그룹에서 프레임 가져오기\n",
    "                    if hasattr(landmarks_group, \"files\"):\n",
    "                        if \"x\" not in landmarks_group.files:\n",
    "                            raise ValueError(f\"'x'키가 없습니다: {landmarks_file}\")\n",
    "                        landmark = landmarks_group[\"x\"].astype(np.float32)\n",
    "\n",
    "                    # 정규화\n",
    "                    landmark = self.normalize_sequence_length(landmark)\n",
    "\n",
    "                    X.append(landmark)\n",
    "\n",
    "                    # 라벨 키를 word_id 또는 word_id + word_gloss로 구성\n",
    "                    label_key = row['word_id']\n",
    "                    y.append(label_key)\n",
    "                    person_ids.append(row['person_id']) # person_id 추가\n",
    "\n",
    "                else:\n",
    "                    failed_files.append(str(landmarks_file))\n",
    "                    print(f\"경고: 파일이 존재하지 않습니다: {landmarks_file}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                failed_files.append(str(landmarks_file))\n",
    "                print(f\"경고: 파일 로딩 실패 {landmarks_file}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if len(X) == 0:\n",
    "            raise ValueError(\"로드된 데이터가 없습니다. 모든 파일 로딩에 실패했습니다.\")\n",
    "\n",
    "        # 데이터 검증\n",
    "        # 리스트 => 넘파이 배열\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        person_ids = np.asarray(person_ids) # person_ids도 넘파이 배열로 변환\n",
    "\n",
    "        # 형태/차원 검증\n",
    "        if X.ndim != 3:\n",
    "            raise ValueError(f\"입력 X차원 오류: 기대 (N, L, F) 3차원, 실제 {X.shape}\")\n",
    "\n",
    "        sample_shape = X[0].shape    # (L, feature_fim)\n",
    "        if sample_shape[1] != self.feature_dim:\n",
    "            raise ValueError(f\"특성 차원 불일치: 예상={self.feature_dim}, 실제={sample_shape[1]}\")\n",
    "\n",
    "        if len(failed_files) > 0:\n",
    "            print(f\"총 {len(failed_files)}개 파일 로딩에 실패했습니다.\")\n",
    "\n",
    "        print(f\"성공적으로 로드된 데이터: {len(X)}개\")\n",
    "        print(f\"데이터 형태: {np.array(X).shape}\")\n",
    "\n",
    "        # 라벨 인코딩 : 'label_key'로 수행\n",
    "        self.label_encoder.fit(y) # 전체 라벨에 대해 fit\n",
    "        y_encoded = self.label_encoder.transform(y)\n",
    "        self.num_classes = len(self.label_encoder.classes_)    # 동적 결정\n",
    "        print(f\"NUM_CLASSES: {self.num_classes}\")\n",
    "        y_categorical = keras.utils.to_categorical(y_encoded, num_classes=self.num_classes)\n",
    "\n",
    "        # person_id 기반 데이터 분할\n",
    "        if validation_person_ids is not None:\n",
    "            print(f\"Person ID {validation_person_ids}를 사용하여 데이터 분할 중...\")\n",
    "            train_indices = np.isin(person_ids, validation_person_ids, invert=True)\n",
    "            val_indices = np.isin(person_ids, validation_person_ids)\n",
    "\n",
    "            X_train, y_train = X[train_indices], y_categorical[train_indices]\n",
    "            X_val, y_val = X[val_indices], y_categorical[val_indices]\n",
    "\n",
    "            print(f\"학습 데이터 (Person ID 제외): {len(X_train)}개\")\n",
    "            print(f\"검증 데이터 (Person ID {validation_person_ids}): {len(X_val)}개\")\n",
    "\n",
    "            if len(X_train) == 0 or len(X_val) == 0:\n",
    "                 print(\"경고: person_id 기반 분할 결과 학습 데이터 또는 검증 데이터가 비어있습니다. 분할 설정을 확인하세요.\")\n",
    "\n",
    "\n",
    "            return X_train, X_val, y_train, y_val, self.label_encoder\n",
    "        else:\n",
    "            print(\"validation_person_ids가 지정되지 않아 전체 데이터를 반환합니다.\")\n",
    "            return X, y_categorical, self.label_encoder # 랜덤 분할 대신 전체 데이터와 인코더 반환\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"load_processed_data 에러: {e}\")\n",
    "        raise\n",
    "\n",
    "# SignLanguageModel 클래스에 메서드 추가\n",
    "SignLanguageModel.load_processed_data = load_processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a4c96f-0eab-49e6-8938-83acb649e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, data_path, validation_split=0.2, num_samples=None, validation_person_ids=None):\n",
    "    \"\"\"\n",
    "    모델 학습\n",
    "\n",
    "    Args:\n",
    "        data_path: 학습 데이터 경로\n",
    "        validation_split: 검증 데이터 비율 (validation_person_ids가 None일 때만 사용)\n",
    "        num_samples: 로드할 샘플 수\n",
    "        validation_person_ids: 검증 세트로 사용할 person_id 리스트 (이 값이 있으면 validation_split 무시)\n",
    "\n",
    "    Returns:\n",
    "        학습 히스토리\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 입력 검증\n",
    "        if validation_person_ids is None and not (0 < validation_split < 1):\n",
    "            raise ValueError(f\"validation_split은 0과 1 사이의 값이어야 합니다. 현재 값: {validation_split}\")\n",
    "\n",
    "        print(\"=== 모델 학습 시작 ===\")\n",
    "\n",
    "        # 데이터 로딩 및 분할\n",
    "        print(\"데이터 로딩 중...\")\n",
    "        if validation_person_ids is not None:\n",
    "            # person_id 기반 분할\n",
    "            X_train, X_val, y_train, y_val, self.label_encoder = self.load_processed_data(\n",
    "                data_path, validation_person_ids=validation_person_ids, num_samples=num_samples\n",
    "            )\n",
    "        else:\n",
    "            # 랜덤 분할 (기존 로직)\n",
    "            X, y, self.label_encoder = self.load_processed_data(data_path, num_samples=num_samples)\n",
    "            if len(X) < 10:\n",
    "                raise ValueError(f\"학습 데이터가 너무 적습니다. 최소 10개 이상 필요합니다. 현재: {len(X)}개\")\n",
    "\n",
    "            print(\"데이터 분할 중...\")\n",
    "            try:\n",
    "                X_train, X_val, y_train, y_val = train_test_split(\n",
    "                    X, y, test_size=validation_split, random_state=42, stratify=y.argmax(axis=1)\n",
    "                )\n",
    "            except ValueError as e:\n",
    "                print(f\"stratify 실패, stratify 없이 분할: {e}\")\n",
    "                X_train, X_val, y_train, y_val = train_test_split(\n",
    "                    X, y, test_size=validation_split, random_state=42\n",
    "                )\n",
    "\n",
    "        if len(X_train) == 0 or len(X_val) == 0:\n",
    "             print(\"경고: 데이터 분할 결과 학습 데이터 또는 검증 데이터가 비어있습니다. 데이터 또는 분할 설정을 확인하세요.\")\n",
    "             return None # 학습 데이터가 없으면 학습 진행하지 않음\n",
    "\n",
    "\n",
    "        print(f\"학습 데이터: {len(X_train)}개, 검증 데이터: {len(X_val)}개\")\n",
    "\n",
    "        # 모델 구성\n",
    "        if self.model is None:\n",
    "            print(\"모델 구성 중...\")\n",
    "            self.build_model()\n",
    "        else:\n",
    "            print(\"기존 모델 사용\")\n",
    "\n",
    "        # 모델 저장 경로 설정\n",
    "        model_save_path = cf.MODEL_SAVE_PATH\n",
    "        if not model_save_path.exists():\n",
    "            model_save_path.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"모델 저장 경로 생성: {model_save_path}\")\n",
    "\n",
    "        # 콜백 설정\n",
    "        callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_accuracy',\n",
    "                patience=cf.PATIENCE,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            # 7회 동안 성능 개선이 없으면 학습률을 50% 씩 낮춰서 실행.\n",
    "            keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=7,\n",
    "                min_lr=1e-7,\n",
    "                verbose=1\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                model_save_path / \"best_model.h5\",\n",
    "                monitor='val_accuracy',\n",
    "                save_best_only=True,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Mixed Precision 설정 (GPU 메모리 최적화)\n",
    "        policy = keras.mixed_precision.Policy('mixed_float16')\n",
    "        keras.mixed_precision.set_global_policy(policy)\n",
    "        print(\"Mixed Precision 활성화\")\n",
    "\n",
    "        augmentor = SignAugmentor()\n",
    "\n",
    "        def augment_fn(x, y):\n",
    "            def aug(z):\n",
    "                z = z.numpy()\n",
    "                z = augmentor.augment(z)\n",
    "                return self.normalize_sequence_length(z).astype(np.float32)\n",
    "                \n",
    "            x = tf.py_function(aug, [x], Tout=tf.float32)\n",
    "            # shape 강제 지정: (sequence_length, feature_dim)\n",
    "            x.set_shape((self.sequence_length, self.feature_dim))\n",
    "            return x, y\n",
    "\n",
    "        train_dataset = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "                         .map(augment_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                         .shuffle(1000)\n",
    "                         .batch(cf.BATCH_SIZE)\n",
    "                         .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "        val_dataset = (tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "                       .batch(cf.BATCH_SIZE)\n",
    "                       .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "        # 학습 실행\n",
    "        print(\"모델 학습 시작...\")\n",
    "        history = self.model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=cf.EPOCHS,\n",
    "            batch_size=cf.BATCH_SIZE,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # 라벨 인코더 저장\n",
    "        print(\"라벨 인코더 저장 중...\")\n",
    "        with open(model_save_path / 'label_encoder.pkl', 'wb') as f:\n",
    "            pickle.dump(self.label_encoder, f)\n",
    "\n",
    "        print(\"=== 학습 완료 ===\")\n",
    "        return history\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"train 에러: {e}\")\n",
    "        raise\n",
    "\n",
    "# SignLanguageModel 클래스에 메서드 추가\n",
    "SignLanguageModel.train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef213a9-4d7a-4468-8c6e-11df754d41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(self):\n",
    "    \"\"\"\n",
    "    CNN(1D + TimeDistributed) + LSTM + MultiHeadAttention 하이브리드 모델\n",
    "    구조:\n",
    "    1. TimeDistributed Conv1D (프레임별 특징 추출)\n",
    "    2. BiLSTM (시계열 패턴 학습)\n",
    "    3. MultiHeadAttention (중요 프레임 강조)\n",
    "    4. Dense (분류)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if self.sequence_length <= 0 or self.feature_dim <= 0:\n",
    "            raise ValueError(\n",
    "                f\"잘못된 입력 크기: sequence_length={self.sequence_length}, feature_dim={self.feature_dim}\"\n",
    "            )\n",
    "\n",
    "        print(\"모델 구성 중...\")\n",
    "\n",
    "        # 입력: (batch, time, feature_dim, 1)\n",
    "        inputs = keras.Input(shape=(self.sequence_length, self.feature_dim, 1))\n",
    "\n",
    "        # --- Conv 블록 1 ---\n",
    "        x = layers.TimeDistributed(\n",
    "            layers.Conv1D(16, 3, activation=\"relu\", padding=\"same\")\n",
    "        )(inputs)\n",
    "        x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "        x = layers.TimeDistributed(layers.MaxPooling1D(2))(x)\n",
    "        x = layers.TimeDistributed(layers.Dropout(cf.DROPOUT_RATE))(x)\n",
    "\n",
    "        # --- Conv 블록 2 ---\n",
    "        x = layers.TimeDistributed(\n",
    "            layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")\n",
    "        )(x)\n",
    "        x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "        x = layers.TimeDistributed(layers.MaxPooling1D(2))(x)\n",
    "        x = layers.TimeDistributed(layers.Dropout(cf.DROPOUT_RATE))(x)\n",
    "\n",
    "        # --- Conv 블록 3 ---\n",
    "        x = layers.TimeDistributed(\n",
    "            layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\")\n",
    "        )(x)\n",
    "        x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
    "        x = layers.TimeDistributed(layers.MaxPooling1D(2))(x)\n",
    "        x = layers.TimeDistributed(layers.Dropout(cf.DROPOUT_RATE))(x)\n",
    "\n",
    "        x = layers.TimeDistributed(layers.Flatten())(x)\n",
    "\n",
    "        # --- LSTM 블록 ---\n",
    "        x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=cf.DROPOUT_RATE))(x)\n",
    "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=cf.DROPOUT_RATE))(x)\n",
    "\n",
    "        print(\"LSTM 출력 shape:\", x.shape)\n",
    "\n",
    "        # --- Attention ---\n",
    "        attention = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "        x = layers.Add()([x, attention])\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "        # --- 분류기 ---\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "\n",
    "        outputs = layers.Dense(\n",
    "            self.num_classes, activation=\"softmax\", dtype=\"float32\"\n",
    "        )(x)\n",
    "\n",
    "        self.model = keras.Model(inputs, outputs)\n",
    "\n",
    "        # --- 컴파일 ---\n",
    "        loss = keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "        self.model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                learning_rate=cf.LEARNING_RATE, clipnorm=1.0\n",
    "            ),\n",
    "            loss=loss,\n",
    "            metrics=[\"accuracy\", keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top5\")],\n",
    "        )\n",
    "\n",
    "        print(\"모델 구성 완료!\")\n",
    "        return self.model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"build_model 에러: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# SignLanguageModel 클래스에 메서드 추가\n",
    "SignLanguageModel.build_model = build_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90291ffb-d56a-4e69-b30e-2201e62298b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(self):\n",
    "#     try:\n",
    "#         if self.sequence_length <= 0 or self.feature_dim <= 0:\n",
    "#             raise ValueError(\n",
    "#                 f\"잘못된 입력 크기: sequence_length={self.sequence_length}, feature_dim={self.feature_dim}\"\n",
    "#             )\n",
    "\n",
    "#         print(\"경량화 모델 구성 중...\")\n",
    "\n",
    "#         # 입력: (batch, time, feature_dim)\n",
    "#         inputs = keras.Input(shape=(self.sequence_length, self.feature_dim))\n",
    "\n",
    "#         # --- Conv 블록 ---\n",
    "#         x = layers.Conv1D(16, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "#         x = layers.MaxPooling1D(2)(x)\n",
    "#         x = layers.Dropout(cf.DROPOUT_RATE)(x)\n",
    "    \n",
    "#         x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "#         x = layers.MaxPooling1D(2)(x)\n",
    "#         x = layers.Dropout(cf.DROPOUT_RATE)(x)\n",
    "\n",
    "#         x = layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "#         x = layers.MaxPooling1D(2)(x)\n",
    "#         x = layers.Dropout(cf.DROPOUT_RATE)(x)\n",
    "\n",
    "#         x = layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "#         x = layers.MaxPooling1D(2)(x)\n",
    "#         x = layers.Dropout(cf.DROPOUT_RATE)(x)\n",
    "\n",
    "#         x = layers.TimeDistributed(layers.Flatten())(x)\n",
    "\n",
    "#         # --- GRU 블록 ---\n",
    "#         x = layers.Bidirectional(layers.GRU(256, return_sequences=True, dropout=cf.DROPOUT_RATE))(x)\n",
    "#         x = layers.Bidirectional(layers.GRU(128, return_sequences=True, dropout=cf.DROPOUT_RATE))(x)\n",
    "#         x = layers.Bidirectional(layers.GRU(64, return_sequences=True, dropout=cf.DROPOUT_RATE))(x)\n",
    "\n",
    "#         # --- Attention ---\n",
    "#         attention = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "#         x = layers.Add()([x, attention])  \n",
    "#         x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "#         # --- 분류기 ---\n",
    "#         x = layers.Dropout(0.3)(x)\n",
    "#         x = layers.Dense(128, activation=\"relu\")(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "#         x = layers.Dropout(0.5)(x)\n",
    "\n",
    "#         outputs = layers.Dense(\n",
    "#             self.num_classes, activation=\"softmax\", dtype=\"float32\"\n",
    "#         )(x)\n",
    "\n",
    "#         self.model = keras.Model(inputs, outputs)\n",
    "\n",
    "#         # --- 컴파일 ---\n",
    "#         loss = keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "#         self.model.compile(\n",
    "#             optimizer=keras.optimizers.Adam(\n",
    "#                 learning_rate=cf.LEARNING_RATE, clipnorm=1.0\n",
    "#             ),\n",
    "#             loss=loss,\n",
    "#             metrics=[\"accuracy\", keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top5\")],\n",
    "#         )\n",
    "\n",
    "#         print(\"경량화 모델 구성 완료!\")\n",
    "#         return self.model\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"build_model 에러: {e}\")\n",
    "#         raise\n",
    "\n",
    "# SignLanguageModel.build_model = build_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdaf4fa-d032-4584-89da-2af05821535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"\n",
    "    학습/검증 Accuracy & Loss 시각화\n",
    "    \"\"\"\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc, label=\"Train Acc\")\n",
    "    plt.plot(val_acc, label=\"Val Acc\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label=\"Train Loss\")\n",
    "    plt.plot(val_loss, label=\"Val Loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ca8dc-5132-4252-84dc-2c76261b1f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ad53d-588e-4f1f-9885-a6d0401b4e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e3be146-0412-4724-8fcf-a3424a3ce6bf",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf1988-86a1-4fbf-a0cb-83e86cfbc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SignLanguageModel 클래스 인스턴스 생성\n",
    "model = SignLanguageModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4972673-85a6-4e18-9410-21fd936e18c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.train(data_path=cf.DATA_ROOT, validation_person_ids=[1, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb1e3a-67d4-4e7f-b181-abf983d46301",
   "metadata": {},
   "source": [
    "- epoch 200\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964a5015-0bda-459f-b68f-da6fd40a0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습이 끝났는데 추가 학습을 하고 싶을 경우 아래의 2 블록을 주석 풀고 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79567f50-c2cc-4d55-8558-aabe4cbee5ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# import pickle\n",
    "# from pathlib import Path\n",
    "\n",
    "# model_instance = SignLanguageModel(\n",
    "# )\n",
    "\n",
    "# model_path = Path(\"BiLSTM_MHAttention_model\") / \"best_model.h5\"\n",
    "# model_instance.model = keras.models.load_model(model_path)\n",
    "\n",
    "# label_encoder_path = model_path.parent / \"label_encoder.pkl\"\n",
    "# with open(label_encoder_path, \"rb\") as f:\n",
    "#     model_instance.label_encoder = pickle.load(f)\n",
    "\n",
    "# # 모델 불러온 뒤 반드시 컴파일 다시 실행\n",
    "# model_instance.model.compile(\n",
    "#     optimizer=keras.optimizers.Adam(learning_rate=cf.LEARNING_RATE, clipnorm=1.0),\n",
    "#     loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "#     metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top5\")]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ba134-fdec-4ffe-b7e9-9c936871238a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = model_instance.train(\n",
    "#     data_path=cf.DATA_ROOT\", validation_person_ids=[1, 3]            # 데이터 샘플 제한 지정 가능\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943cb85c-c999-4626-8b82-635148680654",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56354793-c935-4ace-8273-6ffcd7a5544a",
   "metadata": {},
   "source": [
    "## 평가\n",
    "\n",
    "- 수정중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0abd64f-725b-4548-87fc-c809bb01b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 모델 로드 및 평가\n",
    "\n",
    "def evaluate_best_model(model_instance, data_path, num_samples=None):\n",
    "    \"\"\"\n",
    "    저장된 best 모델을 로드하고 테스트 데이터셋으로 평가\n",
    "\n",
    "    Args:\n",
    "        model_instance: SignLanguageModel 클래스 인스턴스\n",
    "        data_path: 테스트 데이터 경로\n",
    "        num_samples: 로드할 샘플 수 (None이면 전체 로드)\n",
    "\n",
    "    Returns:\n",
    "        테스트 데이터 평가 결과 (딕셔너리 형태)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"=== 테스트 데이터 평가 시작 ===\")\n",
    "\n",
    "        # 테스트 데이터 로딩\n",
    "        print(f\"테스트 데이터 로딩 중: {data_path}\")\n",
    "        X_test, y_test = model_instance.load_processed_data(data_path, num_samples)\n",
    "\n",
    "        if len(X_test) == 0:\n",
    "            print(\"테스트 데이터가 로드되지 않았습니다.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"테스트 데이터: {len(X_test)}개\")\n",
    "\n",
    "        # 저장된 best 모델 로드\n",
    "        model_save_path = cf.MODEL_SAVE_PATH / \"best_model_2_batch32_epoch293.h5\"\n",
    "        if not model_save_path.exists():\n",
    "            raise FileNotFoundError(f\"저장된 best 모델이 없습니다: {model_save_path}\")\n",
    "\n",
    "        print(f\"모델 로딩 중: {model_save_path}\")\n",
    "        loaded_model = keras.models.load_model(model_save_path)\n",
    "\n",
    "        # 모델 평가\n",
    "        print(\"모델 평가 중...\")\n",
    "        loss, accuracy, top5_accuracy = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "        test_results = {\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy,\n",
    "            'top5_accuracy': top5_accuracy\n",
    "        }\n",
    "        print(f\"테스트 결과 - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Top-5 Accuracy: {top5_accuracy:.4f}\")\n",
    "        print(\"=== 테스트 데이터 평가 완료 ===\")\n",
    "\n",
    "        return test_results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"evaluate_best_model 에러: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b0c23-9b74-4a58-b489-3f588a3c6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 테스트 데이터 경로로 수정하세요.\n",
    "test_data_directory = cf.DATA_ROOT # 예시: 학습 데이터와 동일한 경로 사용 (실제와 다를 수 있음)\n",
    "\n",
    "# SignLanguageModel 클래스 인스턴스가 필요합니다. 이미 생성된 'model' 인스턴스를 사용합니다.\n",
    "if 'model' in locals():\n",
    "    test_results = evaluate_best_model(model, test_data_directory, num_samples=10)\n",
    "else:\n",
    "    print(\"SignLanguageModel 인스턴스가 생성되지 않았습니다. 'model = SignLanguageModel()' 코드를 실행하세요.\")\n",
    "\n",
    "if test_results:\n",
    "    print(\"\\n테스트 평가 최종 결과:\")\n",
    "    print(f\"  Loss: {test_results['loss']:.4f}\")\n",
    "    print(f\"  Accuracy: {test_results['accuracy']:.4f}\")\n",
    "    print(f\"  Top-5 Accuracy: {test_results['top5_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b85bb8-bdf3-4a98-a086-5ac788fa14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d3dce-2911-491a-ae60-d6f5e5f560fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip freeze > req.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ddde15-d9df-4dd1-aeee-7d0aab94bb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (signlang)",
   "language": "python",
   "name": "signlang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
